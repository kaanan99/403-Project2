{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abd0ccaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from math import log2, log\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fb5cd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "og_df = pd.read_csv(\"Standardized_Cleaned_Data.csv\")\n",
    "og_df.drop(columns=[\"Unnamed: 0\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07c9ad7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def listToString(s):\n",
    "    '''\n",
    "    s: any list\n",
    "    \n",
    "    output: str built from the elements of the given list\n",
    "    '''\n",
    "    str1 = \"\"\n",
    "    for ele in s:\n",
    "        str1 += (str(ele) + \" \")\n",
    "    return str1[:-1]\n",
    "\n",
    "def gradient_descent_logistic_with_penalty(X, y, learning_rate_val, threshold, L):\n",
    "    '''\n",
    "    X: np.array of our training data\n",
    "    y: np.array of our testing data\n",
    "    learning_rate_val: learning rate\n",
    "    threshold: highest value our gradient can be before we take the betas as they are\n",
    "    L: penalty\n",
    "    \n",
    "    returns np.matrix of our betas\n",
    "    '''\n",
    "    betas = np.matrix(np.zeros(X.shape[1]))\n",
    "    learning_rate = np.array([-1 * learning_rate_val] * betas.shape[1])\n",
    "    stop = False\n",
    "    iterations = 0\n",
    "    while not stop:\n",
    "        y_hat = np.array(X * betas.transpose()).flatten()\n",
    "        exp = np.exp(y_hat)\n",
    "        pi = (exp / (1 + exp))\n",
    "        errors = np.matrix(y-pi)\n",
    "        gradient = np.array((errors * X) / X.shape[0])[0]\n",
    "        beta_vals = np.array(betas)[0]\n",
    "        for x in range(len(gradient)):\n",
    "            if x < 0:\n",
    "                gradient[x] -= beta_vals[x] * L\n",
    "            elif x > 0:\n",
    "                gradient[x] += beta_vals[x] * L\n",
    "        gradient_total = np.sum(abs(gradient))\n",
    "        if (gradient_total < threshold) or (iterations > 6000):\n",
    "            stop = True\n",
    "        betas = -1*(gradient * learning_rate) + betas\n",
    "        iterations += 1\n",
    "#         if iterations % 100 == 0:\n",
    "#             print(gradient_total)\n",
    "    return betas\n",
    "\n",
    "def lda_new(x, y):\n",
    "    '''\n",
    "    x: data minus the target variable\n",
    "    y: target variable\n",
    "    \n",
    "    output: w and c\n",
    "    '''\n",
    "    x[\"Target\"] = y\n",
    "    ones = x[x[\"Target\"] == 1].drop(columns=[\"Target\"])\n",
    "    zeros = x[x[\"Target\"] == 0].drop(columns=[\"Target\"])\n",
    "\n",
    "    sigma_ones = np.cov(np.matrix(ones).transpose()) * (ones.shape[0] - 1)\n",
    "    sigma_zeros = np.cov(np.matrix(zeros).transpose()) * (zeros.shape[0] - 1)\n",
    "    pooled_cov = (sigma_ones + sigma_zeros) / (ones.shape[0] + zeros.shape[0] - 2)\n",
    "    pooled_cov_inv = np.matrix(np.linalg.inv(pooled_cov))\n",
    "\n",
    "    mean1 = np.matrix(np.mean(ones, axis = 0))\n",
    "    mean2 = np.matrix(np.mean(zeros, axis = 0))\n",
    "    mean_diff = (mean1 - mean2).transpose()\n",
    "    mean_sum = (mean1 + mean2).transpose()\n",
    "    #print(mean_diff)\n",
    "\n",
    "    w = pooled_cov_inv * mean_diff\n",
    "    p1 = len(ones)/len(x)\n",
    "    p0 = len(zeros)/len(x)\n",
    "    log_prob = log(p1/p0)\n",
    "\n",
    "    c = ((.5 * mean_sum.transpose()) * w)\n",
    "    #c = log_prob - ((.5 * mean_sum.transpose()) * w)\n",
    "\n",
    "    return w, c\n",
    "\n",
    "def interpret_lda(w, c, X_validation):\n",
    "    '''\n",
    "    w: from lda_new\n",
    "    c: from lda_new\n",
    "    X_validation: test set of data\n",
    "    \n",
    "    output: predictions and probabilities\n",
    "    '''\n",
    "    nums = np.array((np.matrix(X_validation) * w)).flatten()\n",
    "    predictions = []\n",
    "    pi = []\n",
    "    for x in nums:\n",
    "        pi.append(x)\n",
    "        if x > -1 * c[0]:\n",
    "            predictions.append(1)\n",
    "        else:\n",
    "            predictions.append(0)\n",
    "    abs_pi = (pi - min(pi)) / ( max(pi) - min(pi) )\n",
    "    return predictions, abs_pi\n",
    "\n",
    "def new_betas_to_preds(X, new_betas, threshold):\n",
    "    '''\n",
    "    X: data minus the target variable\n",
    "    new_betas: betas found in gradient_descent_logistic_with_penalty\n",
    "    threshold: what probability value we want to use to differentiate between ones and zeroes in our predictions\n",
    "    \n",
    "    output: predictions and probabilities\n",
    "    '''\n",
    "    log_odds = np.matrix(X) * new_betas.transpose()\n",
    "    exp = np.exp(log_odds)\n",
    "    pi = (exp / (1 + exp))\n",
    "    preds = pd.Series([1 if x > threshold else 0 for x in pi])\n",
    "    return preds, pi\n",
    "\n",
    "def my_split(X, y, test_size, split):\n",
    "    '''\n",
    "    X: data minus the target variable\n",
    "    y: the target variable\n",
    "    test_size: the proportion of data we want in the test set\n",
    "    split: \"random\" or \"stratify\" for the type of split we want\n",
    "    \n",
    "    output: X_train, y_train, X_validation, y_validation, X_test, y_test for use in model building and testing\n",
    "    '''\n",
    "    if split == \"random\":\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state = 42)\n",
    "        X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size = .25, random_state = 42)\n",
    "        return X_train, y_train, X_validation, y_validation, X_test, y_test\n",
    "    if split == \"stratify\":\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=test_size, random_state = 42)\n",
    "        X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, stratify=y_train, test_size=test_size, random_state = 42)\n",
    "        return X_train, y_train, X_validation, y_validation, X_test, y_test\n",
    "\n",
    "def get_metrics(y_test, preds, pi):\n",
    "    '''\n",
    "    y_test: actual target var that we're comparing our predictions to\n",
    "    preds: predictions of the target var\n",
    "    pi: probabilities to be used in ROC-AUC calculation\n",
    "    \n",
    "    output: several metrics describing the validity of our model\n",
    "    '''\n",
    "    acc = accuracy_score(y_test.to_list(), preds)\n",
    "    prec = precision_score(y_test.to_list(), preds)\n",
    "    rec = recall_score(y_test.to_list(), preds)\n",
    "    f1 = f1_score(y_test.to_list(), preds)\n",
    "    f2 = fbeta_score(y_test.to_list(), preds, beta = 2)\n",
    "    roc = roc_auc_score(y_test.to_list(), pi)\n",
    "    our_metric = acc * prec * rec\n",
    "    return {\"ROC-AUC\":roc, \"F1-Score\":f1, \"F2-Score\":f2, \"Precision\":prec, \"Recall\":rec, \"Accuracy\":acc, \"Our Metric\":our_metric}\n",
    "\n",
    "def my_downsample(df, zeroes_to_ones):\n",
    "    '''\n",
    "    df: data with target\n",
    "    zeroes_to_ones: how many zeroes do we want for every one in the data\n",
    "    \n",
    "    output: original data but only with all of the 1s and randomly sampled zeroes\n",
    "    '''\n",
    "    just_ones_df = df[df[\"TARGET\"] == 1]\n",
    "    just_zeroes_df =df[df[\"TARGET\"] == 0].sample(n=len(just_ones_df) * zeroes_to_ones, random_state=42)\n",
    "    complete_df = pd.concat([just_ones_df, just_zeroes_df])\n",
    "    return complete_df\n",
    "\n",
    "def extreme_zeroes(df, zeroes_to_ones):\n",
    "    '''\n",
    "    df: data with target\n",
    "    zeroes_to_ones: how many zeroes do we want for every one in the data\n",
    "    \n",
    "    output: original data but only with all of the 1s and only the most extreme zeroes\n",
    "    '''\n",
    "    X = df.drop(columns=[\"TARGET\"])\n",
    "    y = df[\"TARGET\"]\n",
    "    \n",
    "    #Train a basic logistic regression model with lr=.1, cutoff=.3, penalty=0\n",
    "    new_betas = gradient_descent_logistic_with_penalty(np.array(X), y, .1, .03, 0)\n",
    "    preds, pi = new_betas_to_preds(X, new_betas, .5)\n",
    "    #Collect probabilities\n",
    "    X[\"probs\"] = pi\n",
    "    \n",
    "    #Downsample to only include the most extreme n (based on ds_comp) zeroes and all the ones\n",
    "    just_ones_df = df[df[\"TARGET\"] == 1]\n",
    "    ez_indices = X[\"probs\"].sort_values().index[:len(just_ones_df) * zeroes_to_ones].to_list()\n",
    "    just_zeroes_df = df[df.index.isin(ez_indices)]\n",
    "    complete_df = pd.concat([just_ones_df, just_zeroes_df])\n",
    "    return complete_df\n",
    "\n",
    "def build_model(downsample, zeroes_to_ones, split, test_size, PCA_, PCA_var, df):\n",
    "    '''\n",
    "    downsample: \"random\", \"ez\", or None to determine how we downsample the data\n",
    "    zeroes_to_ones: number of zeroes we want for every one in the target variable\n",
    "    split: \"random\" or \"stratified\" to describe how we split our train and test sets\n",
    "    test_size: what portion of the data we want in our test set\n",
    "    PCA_: 1 if we want to apply pca and 0 otherwise\n",
    "    PCA_var: what percentage of the variance do we want explained in our PCA\n",
    "    df: original data\n",
    "    \n",
    "    output: metrics of success for our built model\n",
    "    '''\n",
    "    \n",
    "    X = df.drop(columns=[\"TARGET\"])\n",
    "    y = df[\"TARGET\"]\n",
    "    \n",
    "    if PCA_:\n",
    "        #initialize PCA\n",
    "        pca = PCA(n_components=PCA_var)\n",
    "        #new X with PCA\n",
    "        X = pd.DataFrame(pca.fit_transform(np.array(X)))\n",
    "        #new df with PCA X and initial target\n",
    "        df = pd.concat([X, y], axis = 1)\n",
    "        \n",
    "    ult_X_train, ult_y_train, ult_X_validation, ult_y_validation, ult_X_test, ult_y_test = my_split(X, y, test_size, split)\n",
    "    \n",
    "    if downsample == \"ez\":\n",
    "        df = extreme_zeroes(df, zeroes_to_ones)\n",
    "    elif downsample == \"random\":\n",
    "        df = my_downsample(df, zeroes_to_ones)\n",
    "        \n",
    "    X = df.drop(columns=[\"TARGET\"])\n",
    "    y = df[\"TARGET\"]\n",
    "        \n",
    "    X_train, y_train, X_validation, y_validation, X_test, y_test = my_split(X, y, test_size, split)\n",
    "    \n",
    "    try:\n",
    "        w, c = lda_new(X_train, y_train)\n",
    "        preds, pi = interpret_lda(w, c, ult_X_validation)\n",
    "    except np.linalg.LinAlgError as err:\n",
    "        return \"Linear Algebra Error\"\n",
    "    \n",
    "    return get_metrics(ult_y_validation, preds, pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13bb5594",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\16306\\anaconda3\\envs\\azureml-workshop\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\16306\\anaconda3\\envs\\azureml-workshop\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ROC-AUC': 0.5353817480711208,\n",
       " 'F1-Score': 0.0,\n",
       " 'F2-Score': 0.0,\n",
       " 'Precision': 0.0,\n",
       " 'Recall': 0.0,\n",
       " 'Accuracy': 0.919271574326247,\n",
       " 'Our Metric': 0.0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_model('None', 1, 'stratify', .2, 0, 'x', og_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fe1cc2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downsample = [\"None\", \"random\", \"extreme zeroes\"]\n",
    "ds_comp = [1, 2, 3]\n",
    "split = [\"stratify\", \"random\"]\n",
    "test_size = [.2, .1]\n",
    "PCA_ = [0, 1]\n",
    "PCA_var = [.8, .9, .95]\n",
    "\n",
    "#Order: downsample, ds_comp, split, ratio, threshold\n",
    "\n",
    "combinations = []\n",
    "for a in downsample:\n",
    "    for b in ds_comp:\n",
    "        for c in split:\n",
    "            for d in test_size:\n",
    "                for e in PCA_:\n",
    "                    for f in PCA_var:\n",
    "                        combinations.append([a, b, c, d, e, f])\n",
    "                            \n",
    "new_combinations = []\n",
    "for comb in combinations:\n",
    "    new_comb = comb\n",
    "    if not comb[4]:\n",
    "        new_comb[5] = \"x\"\n",
    "    if comb[0] == \"None\":\n",
    "        ds_comp = \"x\"\n",
    "    new_combinations.append(new_comb)\n",
    "    \n",
    "combinations = []\n",
    "[combinations.append(x) for x in new_combinations if x not in combinations]\n",
    "len(combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "321207c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROC-AUC</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>F2-Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Our Metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>random 1 stratify 0.1 1 0.95</th>\n",
       "      <td>0.742017</td>\n",
       "      <td>0.208112</td>\n",
       "      <td>0.383742</td>\n",
       "      <td>0.118058</td>\n",
       "      <td>0.877350</td>\n",
       "      <td>0.461049</td>\n",
       "      <td>0.047755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random 2 stratify 0.1 1 0.95</th>\n",
       "      <td>0.741940</td>\n",
       "      <td>0.211937</td>\n",
       "      <td>0.386830</td>\n",
       "      <td>0.120863</td>\n",
       "      <td>0.859893</td>\n",
       "      <td>0.483813</td>\n",
       "      <td>0.050282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random 3 stratify 0.1 1 0.95</th>\n",
       "      <td>0.741764</td>\n",
       "      <td>0.208256</td>\n",
       "      <td>0.383937</td>\n",
       "      <td>0.118151</td>\n",
       "      <td>0.877350</td>\n",
       "      <td>0.461519</td>\n",
       "      <td>0.047841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>None 1 stratify 0.1 1 0.95</th>\n",
       "      <td>0.740904</td>\n",
       "      <td>0.202867</td>\n",
       "      <td>0.377592</td>\n",
       "      <td>0.114535</td>\n",
       "      <td>0.886750</td>\n",
       "      <td>0.437491</td>\n",
       "      <td>0.044433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>None 2 stratify 0.1 1 0.95</th>\n",
       "      <td>0.740904</td>\n",
       "      <td>0.202867</td>\n",
       "      <td>0.377592</td>\n",
       "      <td>0.114535</td>\n",
       "      <td>0.886750</td>\n",
       "      <td>0.437491</td>\n",
       "      <td>0.044433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>None 2 stratify 0.1 0 x</th>\n",
       "      <td>0.477383</td>\n",
       "      <td>0.149381</td>\n",
       "      <td>0.305091</td>\n",
       "      <td>0.080720</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.080720</td>\n",
       "      <td>0.006516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>None 3 stratify 0.1 0 x</th>\n",
       "      <td>0.477383</td>\n",
       "      <td>0.149381</td>\n",
       "      <td>0.305091</td>\n",
       "      <td>0.080720</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.080720</td>\n",
       "      <td>0.006516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extreme zeroes 1 stratify 0.1 0 x</th>\n",
       "      <td>0.477383</td>\n",
       "      <td>0.149381</td>\n",
       "      <td>0.305091</td>\n",
       "      <td>0.080720</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.080720</td>\n",
       "      <td>0.006516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extreme zeroes 2 stratify 0.1 0 x</th>\n",
       "      <td>0.477383</td>\n",
       "      <td>0.149381</td>\n",
       "      <td>0.305091</td>\n",
       "      <td>0.080720</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.080720</td>\n",
       "      <td>0.006516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extreme zeroes 3 stratify 0.1 0 x</th>\n",
       "      <td>0.477383</td>\n",
       "      <td>0.149381</td>\n",
       "      <td>0.305091</td>\n",
       "      <td>0.080720</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.080720</td>\n",
       "      <td>0.006516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    ROC-AUC  F1-Score  F2-Score  Precision  \\\n",
       "random 1 stratify 0.1 1 0.95       0.742017  0.208112  0.383742   0.118058   \n",
       "random 2 stratify 0.1 1 0.95       0.741940  0.211937  0.386830   0.120863   \n",
       "random 3 stratify 0.1 1 0.95       0.741764  0.208256  0.383937   0.118151   \n",
       "None 1 stratify 0.1 1 0.95         0.740904  0.202867  0.377592   0.114535   \n",
       "None 2 stratify 0.1 1 0.95         0.740904  0.202867  0.377592   0.114535   \n",
       "...                                     ...       ...       ...        ...   \n",
       "None 2 stratify 0.1 0 x            0.477383  0.149381  0.305091   0.080720   \n",
       "None 3 stratify 0.1 0 x            0.477383  0.149381  0.305091   0.080720   \n",
       "extreme zeroes 1 stratify 0.1 0 x  0.477383  0.149381  0.305091   0.080720   \n",
       "extreme zeroes 2 stratify 0.1 0 x  0.477383  0.149381  0.305091   0.080720   \n",
       "extreme zeroes 3 stratify 0.1 0 x  0.477383  0.149381  0.305091   0.080720   \n",
       "\n",
       "                                     Recall  Accuracy  Our Metric  \n",
       "random 1 stratify 0.1 1 0.95       0.877350  0.461049    0.047755  \n",
       "random 2 stratify 0.1 1 0.95       0.859893  0.483813    0.050282  \n",
       "random 3 stratify 0.1 1 0.95       0.877350  0.461519    0.047841  \n",
       "None 1 stratify 0.1 1 0.95         0.886750  0.437491    0.044433  \n",
       "None 2 stratify 0.1 1 0.95         0.886750  0.437491    0.044433  \n",
       "...                                     ...       ...         ...  \n",
       "None 2 stratify 0.1 0 x            1.000000  0.080720    0.006516  \n",
       "None 3 stratify 0.1 0 x            1.000000  0.080720    0.006516  \n",
       "extreme zeroes 1 stratify 0.1 0 x  1.000000  0.080720    0.006516  \n",
       "extreme zeroes 2 stratify 0.1 0 x  1.000000  0.080720    0.006516  \n",
       "extreme zeroes 3 stratify 0.1 0 x  1.000000  0.080720    0.006516  \n",
       "\n",
       "[126 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "results = {}\n",
    "for c in tqdm(combinations):\n",
    "    metrics = build_model(c[0], c[1], c[2], c[3], c[4], c[5], og_df)\n",
    "    results[listToString(c)] = metrics\n",
    "    \n",
    "better_results = {}\n",
    "for key in results.keys():\n",
    "    if results[key] != \"Linear Algebra Error\":\n",
    "        better_results[key] = results[key]\n",
    "    \n",
    "lda_models = pd.DataFrame(better_results).T\n",
    "lda_models = lda_models[lda_models[\"ROC-AUC\"] != \"x\"]\n",
    "lda_models.sort_values(by=[\"ROC-AUC\", \"F1-Score\"], ascending = False)#.to_csv(\"final_lda_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9a965d",
   "metadata": {},
   "source": [
    "## Error Analysis for Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "279d1c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "downsample = \"random\"\n",
    "zeroes_to_ones = 1\n",
    "split = \"stratify\"\n",
    "test_size = .1\n",
    "PCA_ = 1\n",
    "PCA_var = .95\n",
    "df = og_df.copy()\n",
    "\n",
    "X = df.drop(columns=[\"TARGET\"])\n",
    "y = df[\"TARGET\"]\n",
    "\n",
    "if PCA_:\n",
    "    #initialize PCA\n",
    "    pca = PCA(n_components=PCA_var)\n",
    "    #new X with PCA\n",
    "    X = pd.DataFrame(pca.fit_transform(np.array(X)))\n",
    "    #new df with PCA X and initial target\n",
    "    df = pd.concat([X, y], axis = 1)\n",
    "\n",
    "ult_X_train, ult_y_train, ult_X_validation, ult_y_validation, ult_X_test, ult_y_test = my_split(X, y, test_size, split)\n",
    "\n",
    "if downsample == \"ez\":\n",
    "    df = extreme_zeroes(df, zeroes_to_ones)\n",
    "elif downsample == \"random\":\n",
    "    df = my_downsample(df, zeroes_to_ones)\n",
    "\n",
    "X = df.drop(columns=[\"TARGET\"])\n",
    "y = df[\"TARGET\"]\n",
    "\n",
    "X_train, y_train, X_validation, y_validation, X_test, y_test = my_split(X, y, test_size, split)\n",
    "\n",
    "try:\n",
    "    w, c = lda_new(X_train, y_train)\n",
    "    preds, pi = interpret_lda(w, c, ult_X_validation)\n",
    "except np.linalg.LinAlgError as err:\n",
    "    \"Linear Algebra Error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e72b9065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "false positives: 14642\n",
      "false negatives: 274\n"
     ]
    }
   ],
   "source": [
    "preds = pd.Series(preds)\n",
    "preds.index = ult_y_validation.index\n",
    "pred_vs_true = pd.concat([pd.DataFrame({\"preds\":preds}), \n",
    "           pd.DataFrame({\"actual\":ult_y_validation})], axis=1)\n",
    "\n",
    "errors = pred_vs_true[pred_vs_true[\"preds\"] != pred_vs_true[\"actual\"]]\n",
    "false_positives = pred_vs_true[pred_vs_true[\"preds\"] > pred_vs_true[\"actual\"]].index.to_list()\n",
    "false_negatives = pred_vs_true[pred_vs_true[\"preds\"] < pred_vs_true[\"actual\"]].index.to_list()\n",
    "\n",
    "print(\"false positives:\", len(false_positives))\n",
    "print(\"false negatives:\", len(false_negatives))\n",
    "\n",
    "fp_df = og_df[og_df.index.isin(false_positives)]\n",
    "fn_df = og_df[og_df.index.isin(false_negatives)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
