{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abd0ccaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from math import log2, log\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fb5cd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "og_df = pd.read_csv(\"Standardized_Cleaned_Data.csv\")\n",
    "og_df.drop(columns=[\"Unnamed: 0\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "07c9ad7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def listToString(s):\n",
    "    '''\n",
    "    s: any list\n",
    "    \n",
    "    output: str built from the elements of the given list\n",
    "    '''\n",
    "    str1 = \"\"\n",
    "    for ele in s:\n",
    "        str1 += (str(ele) + \" \")\n",
    "    return str1[:-1]\n",
    "\n",
    "def gradient_descent_logistic_with_penalty(X, y, learning_rate_val, threshold, L):\n",
    "    '''\n",
    "    X: np.array of our training data\n",
    "    y: np.array of our testing data\n",
    "    learning_rate_val: learning rate\n",
    "    threshold: highest value our gradient can be before we take the betas as they are\n",
    "    L: penalty\n",
    "    \n",
    "    returns np.matrix of our betas\n",
    "    '''\n",
    "    betas = np.matrix(np.zeros(X.shape[1]))\n",
    "    learning_rate = np.array([-1 * learning_rate_val] * betas.shape[1])\n",
    "    stop = False\n",
    "    iterations = 0\n",
    "    while not stop:\n",
    "        y_hat = np.array(X * betas.transpose()).flatten()\n",
    "        exp = np.exp(y_hat)\n",
    "        pi = (exp / (1 + exp))\n",
    "        errors = np.matrix(y-pi)\n",
    "        gradient = np.array((errors * X) / X.shape[0])[0]\n",
    "        beta_vals = np.array(betas)[0]\n",
    "        for x in range(len(gradient)):\n",
    "            if x < 0:\n",
    "                gradient[x] -= beta_vals[x] * L\n",
    "            elif x > 0:\n",
    "                gradient[x] += beta_vals[x] * L\n",
    "        gradient_total = np.sum(abs(gradient))\n",
    "        if (gradient_total < threshold) or (iterations > 6000):\n",
    "            stop = True\n",
    "        betas = -1*(gradient * learning_rate) + betas\n",
    "        iterations += 1\n",
    "#         if iterations % 100 == 0:\n",
    "#             print(gradient_total)\n",
    "    return betas\n",
    "\n",
    "def new_betas_to_preds(X, new_betas, threshold):\n",
    "    '''\n",
    "    X: data minus the target variable\n",
    "    new_betas: betas found in gradient_descent_logistic_with_penalty\n",
    "    threshold: what probability value we want to use to differentiate between ones and zeroes in our predictions\n",
    "    \n",
    "    output: predictions and probabilities\n",
    "    '''\n",
    "    log_odds = np.matrix(X) * new_betas.transpose()\n",
    "    exp = np.exp(log_odds)\n",
    "    pi = (exp / (1 + exp))\n",
    "    preds = pd.Series([1 if x > threshold else 0 for x in pi])\n",
    "    return preds, pi\n",
    "\n",
    "def my_split(X, y, test_size, split):\n",
    "    '''\n",
    "    X: data minus the target variable\n",
    "    y: the target variable\n",
    "    test_size: the proportion of data we want in the test set\n",
    "    split: \"random\" or \"stratify\" for the type of split we want\n",
    "    \n",
    "    output: X_train, y_train, X_validation, y_validation, X_test, y_test for use in model building and testing\n",
    "    '''\n",
    "    if split == \"random\":\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state = 42)\n",
    "        X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size = .25, random_state = 42)\n",
    "        return X_train, y_train, X_validation, y_validation, X_test, y_test\n",
    "    if split == \"stratify\":\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=test_size, random_state = 42)\n",
    "        X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, stratify=y_train, test_size=test_size, random_state = 42)\n",
    "        return X_train, y_train, X_validation, y_validation, X_test, y_test\n",
    "\n",
    "def get_metrics(y_test, preds, pi):\n",
    "    '''\n",
    "    y_test: actual target var that we're comparing our predictions to\n",
    "    preds: predictions of the target var\n",
    "    pi: probabilities to be used in ROC-AUC calculation\n",
    "    \n",
    "    output: several metrics describing the validity of our model\n",
    "    '''\n",
    "    acc = accuracy_score(y_test.to_list(), preds)\n",
    "    prec = precision_score(y_test.to_list(), preds)\n",
    "    rec = recall_score(y_test.to_list(), preds)\n",
    "    f1 = f1_score(y_test.to_list(), preds)\n",
    "    f2 = fbeta_score(y_test.to_list(), preds, beta = 2)\n",
    "    roc = roc_auc_score(y_test.to_list(), pi)\n",
    "    our_metric = acc * prec * rec\n",
    "    return {\"ROC-AUC\":roc, \"F1-Score\":f1, \"F2-Score\":f2, \"Precision\":prec, \"Recall\":rec, \"Accuracy\":acc, \"Our Metric\":our_metric}\n",
    "\n",
    "def my_downsample(df, zeroes_to_ones):\n",
    "    '''\n",
    "    df: data with target\n",
    "    zeroes_to_ones: how many zeroes do we want for every one in the data\n",
    "    \n",
    "    output: original data but only with all of the 1s and randomly sampled zeroes\n",
    "    '''\n",
    "    just_ones_df = df[df[\"TARGET\"] == 1]\n",
    "    just_zeroes_df =df[df[\"TARGET\"] == 0].sample(n=len(just_ones_df) * zeroes_to_ones, random_state=42)\n",
    "    complete_df = pd.concat([just_ones_df, just_zeroes_df])\n",
    "    return complete_df\n",
    "\n",
    "def extreme_zeroes(df, zeroes_to_ones):\n",
    "    '''\n",
    "    df: data with target\n",
    "    zeroes_to_ones: how many zeroes do we want for every one in the data\n",
    "    \n",
    "    output: original data but only with all of the 1s and only the most extreme zeroes\n",
    "    '''\n",
    "    X = df.drop(columns=[\"TARGET\"])\n",
    "    y = df[\"TARGET\"]\n",
    "    \n",
    "    #Train a basic logistic regression model with lr=.1, cutoff=.3, penalty=0\n",
    "    new_betas = gradient_descent_logistic_with_penalty(np.array(X), y, .1, .03, 0)\n",
    "    preds, pi = new_betas_to_preds(X, new_betas, .5)\n",
    "    #Collect probabilities\n",
    "    X[\"probs\"] = pi\n",
    "    \n",
    "    #Downsample to only include the most extreme n (based on ds_comp) zeroes and all the ones\n",
    "    just_ones_df = df[df[\"TARGET\"] == 1]\n",
    "    ez_indices = X[\"probs\"].sort_values().index[:len(just_ones_df) * zeroes_to_ones].to_list()\n",
    "    just_zeroes_df = df[df.index.isin(ez_indices)]\n",
    "    complete_df = pd.concat([just_ones_df, just_zeroes_df])\n",
    "    return complete_df\n",
    "\n",
    "def build_model(downsample, zeroes_to_ones, split, test_size, PCA_, PCA_var, threshold, df):\n",
    "    '''\n",
    "    downsample: \"random\", \"ez\", or None to determine how we downsample the data\n",
    "    zeroes_to_ones: number of zeroes we want for every one in the target variable\n",
    "    split: \"random\" or \"stratified\" to describe how we split our train and test sets\n",
    "    test_size: what portion of the data we want in our test set\n",
    "    PCA_: 1 if we want to apply pca and 0 otherwise\n",
    "    PCA_var: what percentage of the variance do we want explained in our PCA\n",
    "    threshold: what probability threshold determines a 1 from a 0 in our predicted values\n",
    "    df: original data\n",
    "    \n",
    "    output: metrics of success for our built model\n",
    "    '''\n",
    "    \n",
    "    X = df.drop(columns=[\"TARGET\"])\n",
    "    y = df[\"TARGET\"]\n",
    "    \n",
    "    if PCA_:\n",
    "        #initialize PCA\n",
    "        pca = PCA(n_components=PCA_var)\n",
    "        #new X with PCA\n",
    "        X = pd.DataFrame(pca.fit_transform(np.array(X)))\n",
    "        #new df with PCA X and initial target\n",
    "        df = pd.concat([X, y], axis = 1)\n",
    "        \n",
    "    ult_X_train, ult_y_train, ult_X_validation, ult_y_validation, ult_X_test, ult_y_test = my_split(X, y, test_size, split)\n",
    "    \n",
    "    if downsample == \"ez\":\n",
    "        df = extreme_zeroes(df, zeroes_to_ones)\n",
    "    elif downsample == \"random\":\n",
    "        df = my_downsample(df, zeroes_to_ones)\n",
    "        \n",
    "    X = df.drop(columns=[\"TARGET\"])\n",
    "    y = df[\"TARGET\"]\n",
    "        \n",
    "    X_train, y_train, X_validation, y_validation, X_test, y_test = my_split(X, y, test_size, split)\n",
    "    \n",
    "    X_train_matrix, y_train_matrix = [np.matrix(X_train), np.matrix(y_train)]\n",
    "    new_betas = gradient_descent_logistic_with_penalty(X_train_matrix, y_train, .1, .03, .001)\n",
    "    preds, pi = new_betas_to_preds(ult_X_validation, new_betas, threshold)\n",
    "    \n",
    "    return get_metrics(ult_y_validation, preds, pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6fe1cc2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "576"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downsample = [\"None\", \"random\", \"extreme zeroes\"]\n",
    "ds_comp = [1, 2, 3]\n",
    "split = [\"stratify\", \"random\"]\n",
    "test_size = [.2, .1]\n",
    "PCA_ = [0, 1]\n",
    "PCA_var = [.8, .9, .95]\n",
    "threshold = [.33, .4, .5, .66]\n",
    "\n",
    "#Order: downsample, ds_comp, split, ratio, threshold\n",
    "\n",
    "combinations = []\n",
    "for a in downsample:\n",
    "    for b in ds_comp:\n",
    "        for c in split:\n",
    "            for d in test_size:\n",
    "                for e in PCA_:\n",
    "                    for f in PCA_var:\n",
    "                        for g in threshold:\n",
    "                            combinations.append([a, b, c, d, e, f, g])\n",
    "                            \n",
    "new_combinations = []\n",
    "for comb in combinations:\n",
    "    new_comb = comb\n",
    "    if not comb[4]:\n",
    "        new_comb[5] = \"x\"\n",
    "    if comb[0] == \"None\":\n",
    "        ds_comp = \"x\"\n",
    "    new_combinations.append(new_comb)\n",
    "    \n",
    "combinations = []\n",
    "[combinations.append(x) for x in new_combinations if x not in combinations]\n",
    "len(combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e61a12dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 576/576 [2:27:20<00:00, 15.35s/it]\n",
      "C:\\Users\\16306\\anaconda3\\envs\\azureml-workshop\\lib\\site-packages\\pandas\\core\\ops\\__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "results = {}\n",
    "for c in tqdm(combinations):\n",
    "    metrics = build_model(c[0], c[1], c[2], c[3], c[4], c[5], c[6], og_df)\n",
    "    results[listToString(c)] = metrics\n",
    "    \n",
    "logres_models = pd.DataFrame(results).T\n",
    "logres_models = logres_models[logres_models[\"ROC-AUC\"] != \"x\"]\n",
    "logres_models.sort_values(by=[\"ROC-AUC\", \"F1-Score\"], ascending = False).to_csv(\"final_logres_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5b818dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROC-AUC</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>F2-Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Our Metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>random 1 stratify 0.1 0 x 0.66</th>\n",
       "      <td>0.745950</td>\n",
       "      <td>0.284906</td>\n",
       "      <td>0.346808</td>\n",
       "      <td>0.219583</td>\n",
       "      <td>0.405551</td>\n",
       "      <td>0.835670</td>\n",
       "      <td>0.074418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random 1 stratify 0.1 0 x 0.5</th>\n",
       "      <td>0.745950</td>\n",
       "      <td>0.255564</td>\n",
       "      <td>0.407689</td>\n",
       "      <td>0.157571</td>\n",
       "      <td>0.675918</td>\n",
       "      <td>0.682143</td>\n",
       "      <td>0.072652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random 1 stratify 0.1 0 x 0.4</th>\n",
       "      <td>0.745950</td>\n",
       "      <td>0.227750</td>\n",
       "      <td>0.403342</td>\n",
       "      <td>0.131985</td>\n",
       "      <td>0.829902</td>\n",
       "      <td>0.545707</td>\n",
       "      <td>0.059774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random 1 stratify 0.1 0 x 0.33</th>\n",
       "      <td>0.745950</td>\n",
       "      <td>0.202252</td>\n",
       "      <td>0.377796</td>\n",
       "      <td>0.113982</td>\n",
       "      <td>0.896598</td>\n",
       "      <td>0.429072</td>\n",
       "      <td>0.043849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random 2 stratify 0.1 0 x 0.5</th>\n",
       "      <td>0.745524</td>\n",
       "      <td>0.288704</td>\n",
       "      <td>0.344411</td>\n",
       "      <td>0.227401</td>\n",
       "      <td>0.395255</td>\n",
       "      <td>0.842788</td>\n",
       "      <td>0.075751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extreme zeroes 3 random 0.2 1 0.8 0.66</th>\n",
       "      <td>0.711492</td>\n",
       "      <td>0.020448</td>\n",
       "      <td>0.013096</td>\n",
       "      <td>0.317365</td>\n",
       "      <td>0.010564</td>\n",
       "      <td>0.917434</td>\n",
       "      <td>0.003076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random 3 random 0.2 1 0.8 0.66</th>\n",
       "      <td>0.711143</td>\n",
       "      <td>0.234861</td>\n",
       "      <td>0.227375</td>\n",
       "      <td>0.248498</td>\n",
       "      <td>0.222643</td>\n",
       "      <td>0.881662</td>\n",
       "      <td>0.048779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random 3 random 0.2 1 0.8 0.5</th>\n",
       "      <td>0.711143</td>\n",
       "      <td>0.219181</td>\n",
       "      <td>0.381241</td>\n",
       "      <td>0.128291</td>\n",
       "      <td>0.751844</td>\n",
       "      <td>0.563022</td>\n",
       "      <td>0.054306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random 3 random 0.2 1 0.8 0.4</th>\n",
       "      <td>0.711143</td>\n",
       "      <td>0.170944</td>\n",
       "      <td>0.336466</td>\n",
       "      <td>0.093931</td>\n",
       "      <td>0.949173</td>\n",
       "      <td>0.248968</td>\n",
       "      <td>0.022197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random 3 random 0.2 1 0.8 0.33</th>\n",
       "      <td>0.711143</td>\n",
       "      <td>0.155384</td>\n",
       "      <td>0.314604</td>\n",
       "      <td>0.084288</td>\n",
       "      <td>0.992824</td>\n",
       "      <td>0.119541</td>\n",
       "      <td>0.010004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>576 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         ROC-AUC  F1-Score  F2-Score  \\\n",
       "random 1 stratify 0.1 0 x 0.66          0.745950  0.284906  0.346808   \n",
       "random 1 stratify 0.1 0 x 0.5           0.745950  0.255564  0.407689   \n",
       "random 1 stratify 0.1 0 x 0.4           0.745950  0.227750  0.403342   \n",
       "random 1 stratify 0.1 0 x 0.33          0.745950  0.202252  0.377796   \n",
       "random 2 stratify 0.1 0 x 0.5           0.745524  0.288704  0.344411   \n",
       "...                                          ...       ...       ...   \n",
       "extreme zeroes 3 random 0.2 1 0.8 0.66  0.711492  0.020448  0.013096   \n",
       "random 3 random 0.2 1 0.8 0.66          0.711143  0.234861  0.227375   \n",
       "random 3 random 0.2 1 0.8 0.5           0.711143  0.219181  0.381241   \n",
       "random 3 random 0.2 1 0.8 0.4           0.711143  0.170944  0.336466   \n",
       "random 3 random 0.2 1 0.8 0.33          0.711143  0.155384  0.314604   \n",
       "\n",
       "                                        Precision    Recall  Accuracy  \\\n",
       "random 1 stratify 0.1 0 x 0.66           0.219583  0.405551  0.835670   \n",
       "random 1 stratify 0.1 0 x 0.5            0.157571  0.675918  0.682143   \n",
       "random 1 stratify 0.1 0 x 0.4            0.131985  0.829902  0.545707   \n",
       "random 1 stratify 0.1 0 x 0.33           0.113982  0.896598  0.429072   \n",
       "random 2 stratify 0.1 0 x 0.5            0.227401  0.395255  0.842788   \n",
       "...                                           ...       ...       ...   \n",
       "extreme zeroes 3 random 0.2 1 0.8 0.66   0.317365  0.010564  0.917434   \n",
       "random 3 random 0.2 1 0.8 0.66           0.248498  0.222643  0.881662   \n",
       "random 3 random 0.2 1 0.8 0.5            0.128291  0.751844  0.563022   \n",
       "random 3 random 0.2 1 0.8 0.4            0.093931  0.949173  0.248968   \n",
       "random 3 random 0.2 1 0.8 0.33           0.084288  0.992824  0.119541   \n",
       "\n",
       "                                        Our Metric  \n",
       "random 1 stratify 0.1 0 x 0.66            0.074418  \n",
       "random 1 stratify 0.1 0 x 0.5             0.072652  \n",
       "random 1 stratify 0.1 0 x 0.4             0.059774  \n",
       "random 1 stratify 0.1 0 x 0.33            0.043849  \n",
       "random 2 stratify 0.1 0 x 0.5             0.075751  \n",
       "...                                            ...  \n",
       "extreme zeroes 3 random 0.2 1 0.8 0.66    0.003076  \n",
       "random 3 random 0.2 1 0.8 0.66            0.048779  \n",
       "random 3 random 0.2 1 0.8 0.5             0.054306  \n",
       "random 3 random 0.2 1 0.8 0.4             0.022197  \n",
       "random 3 random 0.2 1 0.8 0.33            0.010004  \n",
       "\n",
       "[576 rows x 7 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logres_models.sort_values(by=[\"ROC-AUC\", \"F1-Score\"], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9cc243",
   "metadata": {},
   "source": [
    "## Error Analysis for Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0d1ac5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "downsample = \"random\"\n",
    "zeroes_to_ones = 1\n",
    "split = \"stratify\"\n",
    "test_size = .1\n",
    "threshold = .66\n",
    "df = og_df.copy()\n",
    "\n",
    "X = df.drop(columns=[\"TARGET\"])\n",
    "y = df[\"TARGET\"]\n",
    "\n",
    "ult_X_train, ult_y_train, ult_X_validation, ult_y_validation, ult_X_test, ult_y_test = my_split(X, y, test_size, split)\n",
    "\n",
    "if downsample == \"ez\":\n",
    "    df = extreme_zeroes(df, zeroes_to_ones)\n",
    "elif downsample == \"random\":\n",
    "    df = my_downsample(df, zeroes_to_ones)\n",
    "\n",
    "X = df.drop(columns=[\"TARGET\"])\n",
    "y = df[\"TARGET\"]\n",
    "\n",
    "X_train, y_train, X_validation, y_validation, X_test, y_test = my_split(X, y, test_size, split)\n",
    "\n",
    "X_train_matrix, y_train_matrix = [np.matrix(X_train), np.matrix(y_train)]\n",
    "new_betas = gradient_descent_logistic_with_penalty(X_train_matrix, y_train, .1, .03, .001)\n",
    "preds, pi = new_betas_to_preds(ult_X_validation, new_betas, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d551f4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "false positives: 3220\n",
      "false negatives: 1328\n"
     ]
    }
   ],
   "source": [
    "preds.index = ult_y_validation.index\n",
    "pred_vs_true = pd.concat([pd.DataFrame({\"preds\":preds}), \n",
    "           pd.DataFrame({\"actual\":ult_y_validation})], axis=1)\n",
    "\n",
    "errors = pred_vs_true[pred_vs_true[\"preds\"] != pred_vs_true[\"actual\"]]\n",
    "false_positives = pred_vs_true[pred_vs_true[\"preds\"] > pred_vs_true[\"actual\"]].index.to_list()\n",
    "false_negatives = pred_vs_true[pred_vs_true[\"preds\"] < pred_vs_true[\"actual\"]].index.to_list()\n",
    "\n",
    "print(\"false positives:\", len(false_positives))\n",
    "print(\"false negatives:\", len(false_negatives))\n",
    "\n",
    "fp_df = og_df[og_df.index.isin(false_positives)]\n",
    "fn_df = og_df[og_df.index.isin(false_negatives)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f3a2e538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FLAG_MOBIL</th>\n",
       "      <td>3220.0</td>\n",
       "      <td>0.001803</td>\n",
       "      <td>2.168741e-19</td>\n",
       "      <td>0.001803</td>\n",
       "      <td>0.001803</td>\n",
       "      <td>0.001803</td>\n",
       "      <td>0.001803</td>\n",
       "      <td>0.001803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CODE_GENDER_XNA</th>\n",
       "      <td>3220.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_DOCUMENT_12</th>\n",
       "      <td>3220.0</td>\n",
       "      <td>-0.002550</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.002550</td>\n",
       "      <td>-0.002550</td>\n",
       "      <td>-0.002550</td>\n",
       "      <td>-0.002550</td>\n",
       "      <td>-0.002550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NAME_INCOME_TYPE_Student</th>\n",
       "      <td>3220.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NAME_INCOME_TYPE_Unemployed</th>\n",
       "      <td>3220.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NAME_INCOME_TYPE_Businessman</th>\n",
       "      <td>3220.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_DOCUMENT_7</th>\n",
       "      <td>3220.0</td>\n",
       "      <td>-0.013853</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.013853</td>\n",
       "      <td>-0.013853</td>\n",
       "      <td>-0.013853</td>\n",
       "      <td>-0.013853</td>\n",
       "      <td>-0.013853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NAME_FAMILY_STATUS_Unknown</th>\n",
       "      <td>3220.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NAME_INCOME_TYPE_Maternity leave</th>\n",
       "      <td>3220.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TARGET</th>\n",
       "      <td>3220.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   count      mean           std       min  \\\n",
       "FLAG_MOBIL                        3220.0  0.001803  2.168741e-19  0.001803   \n",
       "CODE_GENDER_XNA                   3220.0  0.000000  0.000000e+00  0.000000   \n",
       "FLAG_DOCUMENT_12                  3220.0 -0.002550  0.000000e+00 -0.002550   \n",
       "NAME_INCOME_TYPE_Student          3220.0  0.000000  0.000000e+00  0.000000   \n",
       "NAME_INCOME_TYPE_Unemployed       3220.0  0.000000  0.000000e+00  0.000000   \n",
       "NAME_INCOME_TYPE_Businessman      3220.0  0.000000  0.000000e+00  0.000000   \n",
       "FLAG_DOCUMENT_7                   3220.0 -0.013853  0.000000e+00 -0.013853   \n",
       "NAME_FAMILY_STATUS_Unknown        3220.0  0.000000  0.000000e+00  0.000000   \n",
       "NAME_INCOME_TYPE_Maternity leave  3220.0  0.000000  0.000000e+00  0.000000   \n",
       "TARGET                            3220.0  0.000000  0.000000e+00  0.000000   \n",
       "\n",
       "                                       25%       50%       75%       max  \n",
       "FLAG_MOBIL                        0.001803  0.001803  0.001803  0.001803  \n",
       "CODE_GENDER_XNA                   0.000000  0.000000  0.000000  0.000000  \n",
       "FLAG_DOCUMENT_12                 -0.002550 -0.002550 -0.002550 -0.002550  \n",
       "NAME_INCOME_TYPE_Student          0.000000  0.000000  0.000000  0.000000  \n",
       "NAME_INCOME_TYPE_Unemployed       0.000000  0.000000  0.000000  0.000000  \n",
       "NAME_INCOME_TYPE_Businessman      0.000000  0.000000  0.000000  0.000000  \n",
       "FLAG_DOCUMENT_7                  -0.013853 -0.013853 -0.013853 -0.013853  \n",
       "NAME_FAMILY_STATUS_Unknown        0.000000  0.000000  0.000000  0.000000  \n",
       "NAME_INCOME_TYPE_Maternity leave  0.000000  0.000000  0.000000  0.000000  \n",
       "TARGET                            0.000000  0.000000  0.000000  0.000000  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp_df.describe().T.sort_values(by=\"std\", ascending=False).tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "af59a002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TARGET</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>DAYS_REGISTRATION</th>\n",
       "      <th>...</th>\n",
       "      <th>WALLSMATERIAL_MODE_Mixed</th>\n",
       "      <th>WALLSMATERIAL_MODE_Monolithic</th>\n",
       "      <th>WALLSMATERIAL_MODE_Others</th>\n",
       "      <th>WALLSMATERIAL_MODE_Panel</th>\n",
       "      <th>WALLSMATERIAL_MODE_Stone, brick</th>\n",
       "      <th>WALLSMATERIAL_MODE_Wooden</th>\n",
       "      <th>WALLSMATERIAL_MODE_nan</th>\n",
       "      <th>EMERGENCYSTATE_MODE_No</th>\n",
       "      <th>EMERGENCYSTATE_MODE_Yes</th>\n",
       "      <th>EMERGENCYSTATE_MODE_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1892.0</td>\n",
       "      <td>1892.000000</td>\n",
       "      <td>1892.000000</td>\n",
       "      <td>1892.000000</td>\n",
       "      <td>1892.000000</td>\n",
       "      <td>1892.000000</td>\n",
       "      <td>1892.000000</td>\n",
       "      <td>1892.000000</td>\n",
       "      <td>1892.000000</td>\n",
       "      <td>1892.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1892.000000</td>\n",
       "      <td>1892.000000</td>\n",
       "      <td>1892.000000</td>\n",
       "      <td>1892.000000</td>\n",
       "      <td>1892.000000</td>\n",
       "      <td>1892.000000</td>\n",
       "      <td>1892.000000</td>\n",
       "      <td>1892.000000</td>\n",
       "      <td>1892.00000</td>\n",
       "      <td>1892.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.014069</td>\n",
       "      <td>-0.015524</td>\n",
       "      <td>-0.175163</td>\n",
       "      <td>-0.081956</td>\n",
       "      <td>-0.181812</td>\n",
       "      <td>-0.138584</td>\n",
       "      <td>0.504259</td>\n",
       "      <td>-0.264410</td>\n",
       "      <td>0.195026</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004067</td>\n",
       "      <td>-0.003408</td>\n",
       "      <td>-0.003097</td>\n",
       "      <td>-0.046630</td>\n",
       "      <td>-0.039445</td>\n",
       "      <td>0.009521</td>\n",
       "      <td>0.090538</td>\n",
       "      <td>-0.096669</td>\n",
       "      <td>0.00476</td>\n",
       "      <td>0.091909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010167</td>\n",
       "      <td>-0.045681</td>\n",
       "      <td>-0.077565</td>\n",
       "      <td>0.004325</td>\n",
       "      <td>-0.093677</td>\n",
       "      <td>-0.161133</td>\n",
       "      <td>-0.056266</td>\n",
       "      <td>-0.345417</td>\n",
       "      <td>-0.122497</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024338</td>\n",
       "      <td>-0.029305</td>\n",
       "      <td>-0.025856</td>\n",
       "      <td>-0.041153</td>\n",
       "      <td>-0.029712</td>\n",
       "      <td>0.031731</td>\n",
       "      <td>-0.012146</td>\n",
       "      <td>-0.009101</td>\n",
       "      <td>0.02281</td>\n",
       "      <td>-0.006665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.018978</td>\n",
       "      <td>-0.011807</td>\n",
       "      <td>-0.117982</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.029282</td>\n",
       "      <td>0.033456</td>\n",
       "      <td>0.007807</td>\n",
       "      <td>0.514068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.080354</td>\n",
       "      <td>-0.055886</td>\n",
       "      <td>-0.097443</td>\n",
       "      <td>-0.029065</td>\n",
       "      <td>0.649121</td>\n",
       "      <td>0.001304</td>\n",
       "      <td>0.386048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018978</td>\n",
       "      <td>-0.178864</td>\n",
       "      <td>-0.097956</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.012074</td>\n",
       "      <td>0.599223</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>0.220842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.287783</td>\n",
       "      <td>-0.110764</td>\n",
       "      <td>-0.085263</td>\n",
       "      <td>-0.128839</td>\n",
       "      <td>0.479207</td>\n",
       "      <td>-0.001348</td>\n",
       "      <td>0.047759</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-5.539244</td>\n",
       "      <td>3.795502</td>\n",
       "      <td>-0.048881</td>\n",
       "      <td>2.627587</td>\n",
       "      <td>-0.694283</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004354</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001703</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 251 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       TARGET  CNT_CHILDREN  AMT_INCOME_TOTAL   AMT_CREDIT  AMT_ANNUITY  \\\n",
       "count  1892.0   1892.000000       1892.000000  1892.000000  1892.000000   \n",
       "mean     -1.0      0.014069         -0.015524    -0.175163    -0.081956   \n",
       "std       0.0      0.010167         -0.045681    -0.077565     0.004325   \n",
       "min      -1.0      0.000000         -0.018978    -0.011807    -0.117982   \n",
       "25%      -1.0      0.000000          0.000000    -0.080354    -0.055886   \n",
       "50%      -1.0      0.000000          0.018978    -0.178864    -0.097956   \n",
       "75%      -1.0      0.000000          0.000000    -0.287783    -0.110764   \n",
       "max      -1.0     -5.539244          3.795502    -0.048881     2.627587   \n",
       "\n",
       "       AMT_GOODS_PRICE  REGION_POPULATION_RELATIVE   DAYS_BIRTH  \\\n",
       "count      1892.000000                 1892.000000  1892.000000   \n",
       "mean         -0.181812                   -0.138584     0.504259   \n",
       "std          -0.093677                   -0.161133    -0.056266   \n",
       "min           0.000000                   -0.029282     0.033456   \n",
       "25%          -0.097443                   -0.029065     0.649121   \n",
       "50%           0.000000                   -0.012074     0.599223   \n",
       "75%          -0.085263                   -0.128839     0.479207   \n",
       "max          -0.694283                    0.000000     0.004354   \n",
       "\n",
       "       DAYS_EMPLOYED  DAYS_REGISTRATION  ...  WALLSMATERIAL_MODE_Mixed  \\\n",
       "count    1892.000000        1892.000000  ...               1892.000000   \n",
       "mean       -0.264410           0.195026  ...                 -0.004067   \n",
       "std        -0.345417          -0.122497  ...                 -0.024338   \n",
       "min         0.007807           0.514068  ...                  0.000000   \n",
       "25%         0.001304           0.386048  ...                  0.000000   \n",
       "50%        -0.000237           0.220842  ...                  0.000000   \n",
       "75%        -0.001348           0.047759  ...                  0.000000   \n",
       "max         0.000000           0.001703  ...                  0.000000   \n",
       "\n",
       "       WALLSMATERIAL_MODE_Monolithic  WALLSMATERIAL_MODE_Others  \\\n",
       "count                    1892.000000                1892.000000   \n",
       "mean                       -0.003408                  -0.003097   \n",
       "std                        -0.029305                  -0.025856   \n",
       "min                         0.000000                   0.000000   \n",
       "25%                         0.000000                   0.000000   \n",
       "50%                         0.000000                   0.000000   \n",
       "75%                         0.000000                   0.000000   \n",
       "max                         0.000000                   0.000000   \n",
       "\n",
       "       WALLSMATERIAL_MODE_Panel  WALLSMATERIAL_MODE_Stone, brick  \\\n",
       "count               1892.000000                      1892.000000   \n",
       "mean                  -0.046630                        -0.039445   \n",
       "std                   -0.041153                        -0.029712   \n",
       "min                    0.000000                         0.000000   \n",
       "25%                    0.000000                         0.000000   \n",
       "50%                    0.000000                         0.000000   \n",
       "75%                    0.000000                         0.000000   \n",
       "max                    0.000000                         0.000000   \n",
       "\n",
       "       WALLSMATERIAL_MODE_Wooden  WALLSMATERIAL_MODE_nan  \\\n",
       "count                1892.000000             1892.000000   \n",
       "mean                    0.009521                0.090538   \n",
       "std                     0.031731               -0.012146   \n",
       "min                     0.000000                0.000000   \n",
       "25%                     0.000000                0.000000   \n",
       "50%                     0.000000                0.000000   \n",
       "75%                     0.000000                0.000000   \n",
       "max                     0.000000                0.000000   \n",
       "\n",
       "       EMERGENCYSTATE_MODE_No  EMERGENCYSTATE_MODE_Yes  \\\n",
       "count             1892.000000               1892.00000   \n",
       "mean                -0.096669                  0.00476   \n",
       "std                 -0.009101                  0.02281   \n",
       "min                  0.000000                  0.00000   \n",
       "25%                  0.000000                  0.00000   \n",
       "50%                 -1.000000                  0.00000   \n",
       "75%                  0.000000                  0.00000   \n",
       "max                  0.000000                  0.00000   \n",
       "\n",
       "       EMERGENCYSTATE_MODE_nan  \n",
       "count              1892.000000  \n",
       "mean                  0.091909  \n",
       "std                  -0.006665  \n",
       "min                   0.000000  \n",
       "25%                   0.000000  \n",
       "50%                   1.000000  \n",
       "75%                   0.000000  \n",
       "max                   0.000000  \n",
       "\n",
       "[8 rows x 251 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp_df.describe() - fn_df.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
